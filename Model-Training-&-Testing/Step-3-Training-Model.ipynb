{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.utils import to_categorical\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (346, 150, 150, 3) \tValidation dataset shape: (138, 150, 150, 3)\n",
      "['Ahmed', 'Ahmed', 'Ahmed', 'Ahmed', 'Ahmed', 'Ahmed', 'Ahmed', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Ahsan', 'Anus', 'Anus', 'Anus', 'Anus', 'Anus', 'Anus', 'Anus', 'Anus', 'Anus', 'Anus', 'Anus', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Baber', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Bilal', 'Haider', 'Haider', 'Haider', 'Haider', 'Haider', 'Haider', 'Haider', 'Haider', 'Haider', 'Haider', 'Haider', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Hamna', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Kamran', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Khalid', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Maaz', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'Mir Ahmed Gichki', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohiudeen', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'mohsin', 'Muzammil', 'Muzammil', 'Muzammil', 'Muzammil', 'Muzammil', 'Muzammil', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Muzammil4', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'Osama Ali', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'osama', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saad', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Saqib', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'Sayem', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'taskeen', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'tiham', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'usman', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara', 'wara'] [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "IMG_DIM = (150, 150)\n",
    "\n",
    "train_files = glob.glob('training_data/*')\n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in train_files]\n",
    "train_imgs = np.array(train_imgs)\n",
    "train_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in train_files]\n",
    "\n",
    "validation_files = glob.glob('validation_data/*')\n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img in validation_files]\n",
    "validation_imgs = np.array(validation_imgs)\n",
    "validation_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in validation_files]\n",
    "\n",
    "print('Train dataset shape:', train_imgs.shape, \n",
    "      '\\tValidation dataset shape:', validation_imgs.shape)\n",
    "\n",
    "\n",
    "train_imgs_scaled = train_imgs.astype('float32')\n",
    "validation_imgs_scaled  = validation_imgs.astype('float32')\n",
    "train_imgs_scaled /= 255\n",
    "validation_imgs_scaled /= 255\n",
    "\n",
    "batch_size = 347\n",
    "num_classes = 347\n",
    "epochs =10\n",
    "\n",
    "\n",
    "# encode text category labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder() \n",
    "le.fit(train_labels)\n",
    "train_labels_enc =le.transform(train_labels)\n",
    "train_labels_enc=to_categorical(train_labels_enc)\n",
    "validation_labels_enc = le.transform(validation_labels)\n",
    "validation_labels_enc =to_categorical(validation_labels_enc)\n",
    "print(train_labels,train_labels_enc[2:100])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        9280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36992)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 24)                887832    \n",
      "=================================================================\n",
      "Total params: 971,416\n",
      "Trainable params: 971,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 346 samples, validate on 138 samples\n",
      "Epoch 1/10\n",
      "346/346 [==============================] - 35s 101ms/step - loss: 3.1802 - accuracy: 0.0376 - val_loss: 3.1616 - val_accuracy: 0.0725\n",
      "Epoch 2/10\n",
      "346/346 [==============================] - 29s 85ms/step - loss: 3.1503 - accuracy: 0.0780 - val_loss: 3.0303 - val_accuracy: 0.3478\n",
      "Epoch 3/10\n",
      "346/346 [==============================] - 21s 61ms/step - loss: 3.0212 - accuracy: 0.3295 - val_loss: 2.6411 - val_accuracy: 0.4275\n",
      "Epoch 4/10\n",
      "346/346 [==============================] - 21s 62ms/step - loss: 2.6232 - accuracy: 0.4509 - val_loss: 2.1278 - val_accuracy: 0.3043\n",
      "Epoch 5/10\n",
      "346/346 [==============================] - 22s 65ms/step - loss: 2.0537 - accuracy: 0.3353 - val_loss: 4.1198 - val_accuracy: 0.5435\n",
      "Epoch 6/10\n",
      "346/346 [==============================] - 23s 66ms/step - loss: 4.0605 - accuracy: 0.5607 - val_loss: 2.6164 - val_accuracy: 0.4203\n",
      "Epoch 7/10\n",
      "346/346 [==============================] - 21s 61ms/step - loss: 2.5783 - accuracy: 0.4335 - val_loss: 2.1492 - val_accuracy: 0.7391\n",
      "Epoch 8/10\n",
      "346/346 [==============================] - 21s 61ms/step - loss: 2.0869 - accuracy: 0.7457 - val_loss: 1.2343 - val_accuracy: 0.8623\n",
      "Epoch 9/10\n",
      "346/346 [==============================] - 21s 61ms/step - loss: 1.1236 - accuracy: 0.9046 - val_loss: 0.7472 - val_accuracy: 0.8551\n",
      "Epoch 10/10\n",
      "346/346 [==============================] - 21s 62ms/step - loss: 0.6106 - accuracy: 0.8815 - val_loss: 2.2299 - val_accuracy: 0.6449\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3c2024ad7370>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mepoch_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Train Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "input_shape = (150, 150, 3)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(24, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(x=train_imgs_scaled, y=train_labels_enc,\n",
    "                    validation_data=(validation_imgs_scaled, validation_labels_enc),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle('Basic CNN Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epoch_list = list(range(1,31))\n",
    "ax1.plot(epoch_list, history.history['acc'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_acc'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, 31, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, 31, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('university_data_basic.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
